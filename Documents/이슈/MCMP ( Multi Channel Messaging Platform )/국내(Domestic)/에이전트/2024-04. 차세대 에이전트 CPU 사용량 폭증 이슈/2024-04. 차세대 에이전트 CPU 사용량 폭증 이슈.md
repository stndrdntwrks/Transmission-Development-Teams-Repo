---
문서 타입: 이슈
---

#MMS #차세대_에이전트_CPU_사용량_폭증  #2024/04/03 #이슈해결  


|  프로세스 명  | 버전  | 작성자 | 작성일 / 수정일  |
| :------: | :-: | :-: | :--------: |
| 차세대 에이전트 |  -  | 심정훈 | 2024-08-26 |

---

# 개요 

1. [[#배경]]
	1. [[#당시 고객사 서버 환경]]
2. [[#문제 파악 및 해결]]
	1. [[#문제 발생 시점 < 초기 >]]
	2. [[#문제 발생 시점 < 중기 >]]
		1. [[#Netty 대체 에이전트 자원 사용량]]
		2. [[#HTTP 2.0 / HTTP 1.0]]
		3. [[#스탠다드네트웍스-엡코어 회의 진행]]
	3. [[#문제 발생 시점 < 말기 >]]

---

# 배경

> 2024년 2월 ~ 3월 사이 MCMP(Multi Channel Messaging Platform) 사용 고객사(엡코어)가 주기적으로 차세대 에이전트의 CPU 사용량이 폭증한다는 문의가 지속적으로 들어왔다.

## 당시 고객사 서버 환경

| CPU 코어 수           | 메모리  |
| ------------------ | ---- |
| CPU 8Core, 2.1 Ghz | 8 GB |

당시 **고객사 서버 환경은 8코어 2.1 Ghz, 메모리 8 GB** 서버에 13 대의 에이전트(TPS : 800 설정)를 설치하여 사용 중이었고 아래 이미지와 같이 CPU 사용량이 폭증하는 문제가 발생하였다.

- 고객사 CPU 사용량 이미지
	![[고객사 TOP 로그.png]]


---


# 문제 파악 및 해결

> 문제를 어떤 방식으로 접근하였고 어떠한 테스트를 진행했는지 시간 흐름에 따라 정리하였음.

## 문제 발생 시점 < 초기 >

문제 파악 초기, 차세대 에이전트 CPU 사용량 폭증의 원인을 한정된 자원의 서버에서 많은 에이전트가 높은 TPS 로 메세지 발송 시도하여 발생하는 자원 공유 문제를 원인으로 생각했고 이를 뒷받침하기 위해 아래와 같은 테스트를 진행하였다.

- 테스트 / 자세한 테스트 결과는 [[2024-04-03. 엡코어 에이전트 장애 보고서.pdf]] 참고.
	1. **비슷한 서버 환경(8 Core)** 에서 고객사와 **동일한 수(13대)의 차세대 에이전트를 설치**하여 발송 테스트
	2. **비슷한 서버 환경(8 Core)** 에서 고객사와 **동일한 수(13대)의 레거시 에이전트를 설치**하여 발송 테스트

1번과 2번 테스트의 결과, **모든 에이전트의 고르게 발송되지 못하는 것을 발견하였고 CPU 사용량 주기적으로 폭증하는 것을 확인**하였다. 에이전트가 고르게 발송하지 못하는 것을 **프로세스간 자원 경쟁 및 GC 로 인한 CPU 사용량이 증가하는 것으로 생각**하였고 에이전트가 8코어 환경의 서버에서 TPS 를 100으로 설정했을 때 안정적인 것을 확인하고 100 TPS 로 설정하여 사용하라고 고객사에 전달하였으나 고객사가 적은 TPS 에 만족하지 못하여 **에이전트 당 TPS 를 기존의 절반 정도인 400으로 설정하여 전송하는 것에 합의**하였음.  


## 문제 발생 시점 < 중기 >

에이전트 당 TPS 를 400 으로 낮춘 후에도 **지속적으로 자원 사용량 폭증 문제** 를 해결하기 위하여 아래와 같이 문제 해결 방안을 생각하였다.

- 에이전트 해결 방안
	1. 자원 사용량이 많은 것으로 예상되는 **Webflux 를 Netty 로 대체**하여 사용하는 방안
	2. HTTP 1.1 이 아닌 **HTTP 2.0 을 사용하여 메세지 전송 요청에 들어가는 자원 사용량을 줄이는 방안**
	3. C1 컴파일러와 C2 컴파일러의 **에이전트에 적합한 컴파일 방식으로 변경**하는 방안

1번 방안인 기존 메세지 전송 요청에 사용되는 Webflux 가 아닌 Netty 로 대체하여 메세지 전송 테스트 진행하였으나 CPU 사용량이 

### Netty 대체 에이전트 자원 사용량

> **테스트 환경**
> 
> CPU 코어 수 : 8 코어
> 메모리 사용량 : 8 GB



| 사용 라이브러리 |              C1 컴파일러              |              C2 컴파일러              |
| :------: | :-------------------------------: | :-------------------------------: |
|  Netty   | ![[에이전트 Netty 사용 버전 C1 컴파일러.png]] | ![[에이전트 Netty 사용 버전 C2 컴파일러.png]] |

위와 같이 전송 로직을 Netty 로 대체하였으나 비슷한 CPU 사용량 추이를 보여 WebFlux 의 문제가 아닌 것 같다라고 판단하여 HTTP 2.0 을 사용했을 때 HTTP 1.1 대비 성능 개선 여부 확인을 위한 테스트를 진행하였다.


### HTTP 2.0 / HTTP 1.0


| 사용 라이브러리 | HTTP 1.1                    | HTTP 2.0                        |
| -------- | ---------------------------- | -------------------------------- |
| WebFlux  | ![[에이전트 HTTP 1.1 사용 버전.png]] | ![[에이전트 HTTP 2.0 사용 버전.png.png]] |

HTTP 2.0 의 경우 CPU 사용량 대비 TPS 가 증가하였으나 고객사 및 내부 프로세스에 HTTP 2.0 적용이 어려울 것 같다는 판단하에 해당 부분에 대한 추가 테스트는 진행하지 않았다.


### 스탠다드네트웍스-엡코어 회의 진행

계속해서 테스트 진행하였으나 스탠다드네트웍스와 엡코어 간 소통 문제로 인해 엡코어 측에서 회의 요청하였으며 2024년 4월 3일 엡코어 사옥에 찾아가 회의 진행하였으며 엡코어는 아래의 것들을 요구하였다.

- 엡코어 요구 사항 / 자세한 내용은 [[2024-04-03. 스탠다드네트웍스-엡코어 회의록.pdf]] 참고
	1. 메세지 발송 시 TPS 증가는 이해하나 **발송 시점이 아닐 때 발생**하는 **CPU 사용량 폭증 문제 해결**
	2. CPU 사용량이 폭증하는 시점, 특정 에이전트가 발송을 거의 못하는 경우가 있으며 **에이전트 재기동 시 발생하는 메세지 유실 문제 해결**
	3. 에이전트 **바이너리 버전 명시**

기존 테스트는 프로세스 기동 후 메세지 발송 시점의 CPU 사용량 관련한 테스트가 주로 진행하여 해당 요구 사항 반영하여 이후 추가 테스트 진행하였다.


## 문제 발생 시점 < 말기 >

스탠다드네트웍스-엡코어 회의 이후 프로세스 기동하여 대량의 메세지 전송이후 CPU 사용량이 증가하는지 여부를 확인하는 테스트를 진행하였다.

### 차세대 에이전트 특이점 발견 

차세대 에이전트 메모리 사용량 특이점 발견
	![[에이전트 특이점 발견.png]]


차세대 에이전트가 메세지 발송 이후, 메세지 발송 작업을 하지 않음에도 불구하고 위의 그래프처럼 일정 시간이 지났을 때 메모리 사용량이 계단 식으로 증가하다가 어느 순간 메모리 사용량이 줄지 않는 현상을 발견하였다.

분명하게 프로세스에 특이점이 존재하는 것으로 예상되나 기존의 테스트 및 메세지 발송 시점이 아닌 시점에 메모리 사용량이 증가하는 것으로 보아 메세지 전송부 로직에 특이사항이 있을 것이라고는 생각할 수 없었고 외부 라이브러리에서 발생하는 문제일 가능성을 염두하여 당시 메세지 영속성을 보장하기 위하여 사용하던 [ChronicleMap / 버전 3.20.83](https://github.com/OpenHFT/Chronicle-Map) 을 `java.util.Map` 으로 대체하여 추가 테스트 진행하였다.

- `java.util.Map` 대체 테스트 결과
	![[에이전트 java.util.Map 대체 테스트 결과.png]]


ChronicleMap 라이브러리 사용하던 부분을 `java.util.Map` 으로 대체 후, 메모리 사용량이 높아 GC 가 돌아 CPU 사용량도 덩달아 높아지던 현상이 해소되었으며 에이전트에서 발생하던 CPU 사용량 폭증 문제는 해결되었다.


---